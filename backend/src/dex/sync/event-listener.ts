import { createPublicClient, http, parseAbiItem, decodeEventLog } from 'viem';
import type { Address, Log } from 'viem';
import { bsc, bscTestnet } from 'viem/chains';
import { drizzle } from 'drizzle-orm/d1';
import { and, eq, gt, max } from 'drizzle-orm';
import * as schema from '../../database/schema';
import type { Env } from '../../index';

// Trader Joe LiquiBookäº‹ä»¶ABI
const TRADER_JOE_EVENTS = {
  // Swapäº‹ä»¶
  Swap: parseAbiItem('event Swap(address indexed sender, address indexed to, uint24 indexed id, bytes32 amountsIn, bytes32 amountsOut, uint24 volatilityAccumulator, bytes32 totalFees, bytes32 protocolFees)'),
  
  // æµåŠ¨æ€§æ·»åŠ äº‹ä»¶
  DepositedToBins: parseAbiItem('event DepositedToBins(address indexed sender, address indexed to, uint256[] ids, bytes32[] amounts)'),
  
  // æµåŠ¨æ€§ç§»é™¤äº‹ä»¶
  WithdrawnFromBins: parseAbiItem('event WithdrawnFromBins(address indexed sender, address indexed to, uint256[] ids, bytes32[] amounts)'),
  
  // æ± åˆ›å»ºäº‹ä»¶
  LBPairCreated: parseAbiItem('event LBPairCreated(address indexed tokenX, address indexed tokenY, uint256 indexed binStep, address LBPair, uint256 pid)'),
  
  // æµåŠ¨æ€§å˜åŒ–äº‹ä»¶
  CompositionFees: parseAbiItem('event CompositionFees(address indexed sender, address indexed to, uint256[] ids, bytes32[] fees)'),
  
  // ä»·æ ¼å˜åŒ–äº‹ä»¶
  OracleLengthIncreased: parseAbiItem('event OracleLengthIncreased(uint256 previousLength, uint256 newLength)')
};

export interface SyncProgress {
  chain: string;
  contractAddress: string;
  eventType: string;
  lastBlockNumber: bigint;
  lastLogIndex: number;
}

export interface ParsedSwapEvent {
  txHash: string;
  poolAddress: string;
  chain: string;
  sender: string;
  to: string;
  binId: number;
  amountsIn: string;
  amountsOut: string;
  totalFees: string;
  blockNumber: bigint;
  logIndex: number;
  timestamp: number;
}

export interface ParsedLiquidityEvent {
  txHash: string;
  poolAddress: string;
  chain: string;
  user: string;
  to: string;
  eventType: 'deposit' | 'withdraw';
  binIds: number[];
  amounts: string[];
  blockNumber: bigint;
  logIndex: number;
  timestamp: number;
}

export class EventListener {
  private db: ReturnType<typeof drizzle>;
  private publicClient: any;
  private chain: string;
  
  constructor(env: Env, chain: 'bsc' | 'bsc-testnet') {
    this.db = drizzle(env.D1_DATABASE!, { schema });
    this.chain = chain;
    
    // åˆ›å»ºå…¬å…±å®¢æˆ·ç«¯
    const rpcUrl = chain === 'bsc' ? env.BSC_INFURA_URL : env.BSC_TEST_INFURA_URL;
    const chainConfig = chain === 'bsc' ? bsc : bscTestnet;
    
    if (!rpcUrl) {
      throw new Error(`RPC URL not configured for chain: ${chain}`);
    }
    
    this.publicClient = createPublicClient({
      chain: chainConfig,
      transport: http(rpcUrl)
    });
  }

  /**
   * è·å–æŒ‡å®šåˆçº¦çš„åŒæ­¥è¿›åº¦
   */
  async getSyncProgress(contractAddress: string, eventType: string): Promise<SyncProgress | null> {
    try {
      const result = await this.db
        .select()
        .from(schema.syncStatus)
        .where(
          and(
            eq(schema.syncStatus.chain, this.chain),
            eq(schema.syncStatus.contractAddress, contractAddress.toLowerCase()),
            eq(schema.syncStatus.eventType, eventType)
          )
        )
        .limit(1);

      if (result.length === 0) {
        return null;
      }

      const record = result[0];
      if (!record) {
        return null;
      }

      return {
        chain: record.chain,
        contractAddress: record.contractAddress,
        eventType: record.eventType,
        lastBlockNumber: BigInt(record.lastBlockNumber),
        lastLogIndex: record.lastLogIndex
      };
    } catch (error) {
      console.error('Failed to get sync progress:', error);
      return null;
    }
  }

  /**
   * æ›´æ–°åŒæ­¥è¿›åº¦
   */
  async updateSyncProgress(
    contractAddress: string,
    eventType: string,
    blockNumber: bigint,
    logIndex: number
  ): Promise<void> {
    try {
      const now = Date.now();
      
      // å°è¯•æ›´æ–°ç°æœ‰è®°å½•
      const existing = await this.db
        .select()
        .from(schema.syncStatus)
        .where(
          and(
            eq(schema.syncStatus.chain, this.chain),
            eq(schema.syncStatus.contractAddress, contractAddress.toLowerCase()),
            eq(schema.syncStatus.eventType, eventType)
          )
        )
        .limit(1);

      if (existing.length > 0) {
        await this.db
          .update(schema.syncStatus)
          .set({
            lastBlockNumber: Number(blockNumber),
            lastLogIndex: logIndex,
            updatedAt: new Date(now)
          })
          .where(eq(schema.syncStatus.id, existing[0]!.id));
      } else {
        // åˆ›å»ºæ–°è®°å½•
        await this.db.insert(schema.syncStatus).values({
          chain: this.chain,
          contractAddress: contractAddress.toLowerCase(),
          eventType,
          lastBlockNumber: Number(blockNumber),
          lastLogIndex: logIndex,
          updatedAt: new Date(now)
        });
      }
    } catch (error) {
      console.error('Failed to update sync progress:', error);
      throw error;
    }
  }

  /**
   * ç›‘å¬Swapäº‹ä»¶
   */
  async listenToSwapEvents(
    poolAddress: string,
    fromBlock?: bigint,
    toBlock?: bigint
  ): Promise<ParsedSwapEvent[]> {
    try {
      console.log(`Listening to Swap events for pool ${poolAddress} from block ${fromBlock} to ${toBlock}`);
      
      const logs = await this.publicClient.getLogs({
        address: poolAddress as Address,
        event: TRADER_JOE_EVENTS.Swap,
        fromBlock: fromBlock || 'earliest',
        toBlock: toBlock || 'latest'
      });

      const parsedEvents: ParsedSwapEvent[] = [];

      for (const log of logs) {
        try {
          const decoded = decodeEventLog({
            abi: [TRADER_JOE_EVENTS.Swap],
            data: log.data,
            topics: log.topics
          });

          // è·å–åŒºå—ä¿¡æ¯ä»¥è·å–æ—¶é—´æˆ³
          const block = await this.publicClient.getBlock({ blockHash: log.blockHash });
          
          const parsedEvent: ParsedSwapEvent = {
            txHash: log.transactionHash!,
            poolAddress: poolAddress.toLowerCase(),
            chain: this.chain,
            sender: (decoded.args as any).sender,
            to: (decoded.args as any).to,
            binId: Number((decoded.args as any).id),
            amountsIn: (decoded.args as any).amountsIn,
            amountsOut: (decoded.args as any).amountsOut,
            totalFees: (decoded.args as any).totalFees,
            blockNumber: log.blockNumber!,
            logIndex: log.logIndex!,
            timestamp: Number(block.timestamp) * 1000
          };

          parsedEvents.push(parsedEvent);
        } catch (decodeError) {
          console.error('Failed to decode swap event:', decodeError);
          continue;
        }
      }

      console.log(`Found ${parsedEvents.length} swap events`);
      return parsedEvents;
    } catch (error) {
      console.error('Failed to listen to swap events:', error);
      throw error;
    }
  }

  /**
   * ç›‘å¬æµåŠ¨æ€§äº‹ä»¶ï¼ˆå­˜å…¥å’Œæå–ï¼‰
   */
  async listenToLiquidityEvents(
    poolAddress: string,
    fromBlock?: bigint,
    toBlock?: bigint
  ): Promise<ParsedLiquidityEvent[]> {
    try {
      console.log(`Listening to Liquidity events for pool ${poolAddress} from block ${fromBlock} to ${toBlock}`);
      
      // è·å–å­˜å…¥äº‹ä»¶
      const depositLogs = await this.publicClient.getLogs({
        address: poolAddress as Address,
        event: TRADER_JOE_EVENTS.DepositedToBins,
        fromBlock: fromBlock || 'earliest',
        toBlock: toBlock || 'latest'
      });

      // è·å–æå–äº‹ä»¶
      const withdrawLogs = await this.publicClient.getLogs({
        address: poolAddress as Address,
        event: TRADER_JOE_EVENTS.WithdrawnFromBins,
        fromBlock: fromBlock || 'earliest',
        toBlock: toBlock || 'latest'
      });

      const parsedEvents: ParsedLiquidityEvent[] = [];

      // å¤„ç†å­˜å…¥äº‹ä»¶
      for (const log of depositLogs) {
        try {
          const decoded = decodeEventLog({
            abi: [TRADER_JOE_EVENTS.DepositedToBins],
            data: log.data,
            topics: log.topics
          });

          const block = await this.publicClient.getBlock({ blockHash: log.blockHash });
          
          const parsedEvent: ParsedLiquidityEvent = {
            txHash: log.transactionHash!,
            poolAddress: poolAddress.toLowerCase(),
            chain: this.chain,
            user: (decoded.args as any).sender,
            to: (decoded.args as any).to,
            eventType: 'deposit',
            binIds: (decoded.args as any).ids.map((id: bigint) => Number(id)),
            amounts: (decoded.args as any).amounts,
            blockNumber: log.blockNumber!,
            logIndex: log.logIndex!,
            timestamp: Number(block.timestamp) * 1000
          };

          parsedEvents.push(parsedEvent);
        } catch (decodeError) {
          console.error('Failed to decode deposit event:', decodeError);
          continue;
        }
      }

      // å¤„ç†æå–äº‹ä»¶
      for (const log of withdrawLogs) {
        try {
          const decoded = decodeEventLog({
            abi: [TRADER_JOE_EVENTS.WithdrawnFromBins],
            data: log.data,
            topics: log.topics
          });

          const block = await this.publicClient.getBlock({ blockHash: log.blockHash });
          
          const parsedEvent: ParsedLiquidityEvent = {
            txHash: log.transactionHash!,
            poolAddress: poolAddress.toLowerCase(),
            chain: this.chain,
            user: (decoded.args as any).sender,
            to: (decoded.args as any).to,
            eventType: 'withdraw',
            binIds: (decoded.args as any).ids.map((id: bigint) => Number(id)),
            amounts: (decoded.args as any).amounts,
            blockNumber: log.blockNumber!,
            logIndex: log.logIndex!,
            timestamp: Number(block.timestamp) * 1000
          };

          parsedEvents.push(parsedEvent);
        } catch (decodeError) {
          console.error('Failed to decode withdraw event:', decodeError);
          continue;
        }
      }

      // æŒ‰åŒºå—å·å’Œæ—¥å¿—ç´¢å¼•æ’åº
      parsedEvents.sort((a, b) => {
        if (a.blockNumber !== b.blockNumber) {
          return Number(a.blockNumber - b.blockNumber);
        }
        return a.logIndex - b.logIndex;
      });

      console.log(`Found ${parsedEvents.length} liquidity events`);
      return parsedEvents;
    } catch (error) {
      console.error('Failed to listen to liquidity events:', error);
      throw error;
    }
  }

  /**
   * æ‰¹é‡åŒæ­¥æŒ‡å®šåŒºå—èŒƒå›´çš„äº‹ä»¶
   */
  async syncEventsBatch(
    poolAddress: string,
    fromBlock: bigint,
    toBlock: bigint,
    batchSize: bigint = 100n
  ): Promise<void> {
    try {
      console.log(`ğŸ”„ Starting batch sync for pool ${poolAddress} from ${fromBlock} to ${toBlock} (${toBlock - fromBlock + 1n} blocks)`);
      
      let currentFromBlock = fromBlock;
      let totalSwapEvents = 0;
      let totalLiquidityEvents = 0;
      
      while (currentFromBlock <= toBlock) {
        const currentToBlock = currentFromBlock + batchSize > toBlock 
          ? toBlock 
          : currentFromBlock + batchSize;

        console.log(`ğŸ“¦ Syncing batch: ${currentFromBlock} to ${currentToBlock} (${currentToBlock - currentFromBlock + 1n} blocks)`);

        try {
          // åŒæ­¥Swapäº‹ä»¶
          const swapEvents = await this.listenToSwapEvents(
            poolAddress,
            currentFromBlock,
            currentToBlock
          );

          // åŒæ­¥æµåŠ¨æ€§äº‹ä»¶
          const liquidityEvents = await this.listenToLiquidityEvents(
            poolAddress,
            currentFromBlock,
            currentToBlock
          );

          console.log(`ğŸ“Š Found ${swapEvents.length} swap events and ${liquidityEvents.length} liquidity events in batch`);

          // ä¿å­˜äº‹ä»¶åˆ°æ•°æ®åº“
          if (swapEvents.length > 0) {
            console.log(`ğŸ’¾ Saving ${swapEvents.length} swap events to database...`);
            await this.saveSwapEvents(swapEvents);
            totalSwapEvents += swapEvents.length;
            console.log(`âœ… Successfully saved ${swapEvents.length} swap events`);
          }

          if (liquidityEvents.length > 0) {
            console.log(`ğŸ’¾ Saving ${liquidityEvents.length} liquidity events to database...`);
            await this.saveLiquidityEvents(liquidityEvents);
            totalLiquidityEvents += liquidityEvents.length;
            console.log(`âœ… Successfully saved ${liquidityEvents.length} liquidity events`);
          }

          // æ›´æ–°åŒæ­¥è¿›åº¦
          console.log(`ğŸ“ˆ Updating sync progress to block ${currentToBlock}...`);
          await this.updateSyncProgress(
            poolAddress,
            'swap',
            currentToBlock,
            0
          );

          await this.updateSyncProgress(
            poolAddress,
            'liquidity',
            currentToBlock,
            0
          );
          console.log(`âœ… Sync progress updated to block ${currentToBlock}`);

        } catch (batchError) {
          console.error(`âŒ Failed to process batch ${currentFromBlock}-${currentToBlock}:`, batchError);
          
          // æ£€æŸ¥æ˜¯å¦æ˜¯æ•°æ®åº“é”™è¯¯
          if (batchError instanceof Error && batchError.message.includes('database')) {
            console.error(`ğŸ—„ï¸  Database error in batch processing - this will cause missing data`);
          }
          
          // å¯¹äºæ‰¹æ¬¡é”™è¯¯ï¼Œæˆ‘ä»¬ä»ç„¶æ›´æ–°è¿›åº¦ä»¥é¿å…é‡å¤å¤„ç†ç›¸åŒåŒºå—
          await this.updateSyncProgress(
            poolAddress,
            'swap',
            currentToBlock,
            0
          ).catch(progressError => {
            console.error(`âŒ Failed to update progress after batch error:`, progressError);
          });
        }

        currentFromBlock = currentToBlock + 1n;
        
        // æ·»åŠ å°å»¶è¿Ÿé¿å…RPCé™åˆ¶
        await new Promise(resolve => setTimeout(resolve, 100));
      }

      console.log(`âœ… Batch sync completed for pool ${poolAddress}`);
      console.log(`ğŸ“Š Total events saved: ${totalSwapEvents} swap events, ${totalLiquidityEvents} liquidity events`);
      
      if (totalSwapEvents === 0 && totalLiquidityEvents === 0) {
        console.warn(`âš ï¸  No events found for pool ${poolAddress} in ${toBlock - fromBlock + 1n} blocks. This could indicate:
          1. Pool has no activity in this block range
          2. Incorrect pool address
          3. RPC connection issues
          4. Event signature mismatch`);
      }
      
    } catch (error) {
      console.error(`âŒ Failed to sync events batch for pool ${poolAddress}:`, error);
      throw error;
    }
  }

  /**
   * ä¿å­˜Swapäº‹ä»¶åˆ°æ•°æ®åº“
   */
  private async saveSwapEvents(events: ParsedSwapEvent[]): Promise<void> {
    if (events.length === 0) {
      console.log(`â„¹ï¸  No swap events to save`);
      return;
    }

    try {
      console.log(`ğŸ’¾ Preparing to save ${events.length} swap events to database...`);
      
      // æ‰¹é‡æ’å…¥swapäº‹ä»¶
      const swapRecords = events.map(event => ({
        txHash: event.txHash,
        poolAddress: event.poolAddress,
        chain: event.chain,
        sender: event.sender,
        to: event.to,
        tokenInAddress: '', // éœ€è¦ä»æ± ä¿¡æ¯ä¸­è·å–
        tokenOutAddress: '', // éœ€è¦ä»æ± ä¿¡æ¯ä¸­è·å–
        amountIn: event.amountsIn,
        amountOut: event.amountsOut,
        fees: event.totalFees,
        blockNumber: Number(event.blockNumber),
        logIndex: event.logIndex,
        timestamp: new Date(event.timestamp)
      }));

      console.log(`ğŸ”— Sample swap event data:`, {
        txHash: swapRecords[0]?.txHash,
        poolAddress: swapRecords[0]?.poolAddress,
        chain: swapRecords[0]?.chain,
        blockNumber: swapRecords[0]?.blockNumber,
        timestamp: swapRecords[0]?.timestamp
      });

      await this.db.insert(schema.swapEvents).values(swapRecords);
      console.log(`âœ… Successfully saved ${swapRecords.length} swap events to database`);
      
    } catch (error) {
      console.error(`âŒ Failed to save ${events.length} swap events to database:`, error);
      
      // æä¾›æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
      if (error instanceof Error) {
        if (error.message.includes('UNIQUE constraint')) {
          console.error(`ğŸ”„ Duplicate event detected - some events may have been already processed`);
        } else if (error.message.includes('database')) {
          console.error(`ğŸ—„ï¸  Database connection or schema issue`);
        } else if (error.message.includes('permission')) {
          console.error(`ğŸ”’ Database permission issue`);
        }
      }
      
      throw error;
    }
  }

  /**
   * ä¿å­˜æµåŠ¨æ€§äº‹ä»¶åˆ°æ•°æ®åº“
   */
  private async saveLiquidityEvents(events: ParsedLiquidityEvent[]): Promise<void> {
    if (events.length === 0) {
      console.log(`â„¹ï¸  No liquidity events to save`);
      return;
    }

    try {
      console.log(`ğŸ’¾ Preparing to save ${events.length} liquidity events to database...`);
      
      const liquidityRecords = events.map(event => ({
        txHash: event.txHash,
        poolAddress: event.poolAddress,
        chain: event.chain,
        user: event.user,
        eventType: event.eventType,
        binIds: JSON.stringify(event.binIds),
        amounts: JSON.stringify(event.amounts),
        liquidity: '0', // éœ€è¦è®¡ç®—
        blockNumber: Number(event.blockNumber),
        logIndex: event.logIndex,
        timestamp: new Date(event.timestamp)
      }));

      console.log(`ğŸ”— Sample liquidity event data:`, {
        txHash: liquidityRecords[0]?.txHash,
        poolAddress: liquidityRecords[0]?.poolAddress,
        chain: liquidityRecords[0]?.chain,
        eventType: liquidityRecords[0]?.eventType,
        blockNumber: liquidityRecords[0]?.blockNumber,
        timestamp: liquidityRecords[0]?.timestamp
      });

      await this.db.insert(schema.liquidityEvents).values(liquidityRecords);
      console.log(`âœ… Successfully saved ${liquidityRecords.length} liquidity events to database`);
      
    } catch (error) {
      console.error(`âŒ Failed to save ${events.length} liquidity events to database:`, error);
      
      // æä¾›æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
      if (error instanceof Error) {
        if (error.message.includes('UNIQUE constraint')) {
          console.error(`ğŸ”„ Duplicate event detected - some events may have been already processed`);
        } else if (error.message.includes('database')) {
          console.error(`ğŸ—„ï¸  Database connection or schema issue`);
        } else if (error.message.includes('permission')) {
          console.error(`ğŸ”’ Database permission issue`);
        }
      }
      
      throw error;
    }
  }

  /**
   * è·å–æœ€æ–°åŒºå—å·
   */
  async getLatestBlockNumber(): Promise<bigint> {
    try {
      const blockNumber = await this.publicClient.getBlockNumber();
      return blockNumber;
    } catch (error) {
      console.error('Failed to get latest block number:', error);
      throw error;
    }
  }

  /**
   * å¢é‡åŒæ­¥ï¼šä»ä¸Šæ¬¡åŒæ­¥ç‚¹ç»§ç»­åŒæ­¥
   */
  /**
   * è·å–åˆçº¦åˆ›å»ºåŒºå—å·ï¼ˆä¼˜å…ˆLBPairCreatedäº‹ä»¶ï¼Œå¦åˆ™äºŒåˆ†æŸ¥æ‰¾æœ‰codeåŒºå—ï¼‰
   */
  async getContractCreationBlock(contractAddress: string): Promise<bigint> {
    try {
      // ä¼˜å…ˆæŸ¥LBPairCreatedäº‹ä»¶
      const txList = await this.publicClient.getLogs({
        address: contractAddress as Address,
        fromBlock: 0n,
        toBlock: 'latest',
        event: TRADER_JOE_EVENTS.LBPairCreated,
      });
      if (txList.length > 0) {
        return txList[0].blockNumber!;
      }
      // æ²¡æœ‰LBPairCreatedäº‹ä»¶åˆ™äºŒåˆ†æŸ¥æ‰¾æœ‰codeåŒºå—
      let low = 0n;
      let high = await this.getLatestBlockNumber();
      let creationBlock = high;
      while (low <= high) {
        const mid = (low + high) / 2n;
        const code = await this.publicClient.getBytecode({ address: contractAddress as Address, blockNumber: mid });
        if (code && code !== '0x') {
          creationBlock = mid;
          high = mid - 1n;
        } else {
          low = mid + 1n;
        }
      }
      return creationBlock;
    } catch (error) {
      console.error('Failed to get contract creation block:', error);
      // fallback: å›æº¯10000åŒºå—
      return (await this.getLatestBlockNumber()) - 10000n;
    }
  }

  /**
   * å¢é‡åŒæ­¥ï¼šä»ä¸Šæ¬¡åŒæ­¥ç‚¹ç»§ç»­åŒæ­¥ï¼ˆé¦–æ¬¡è‡ªåŠ¨ä»åˆçº¦åˆ›å»ºåŒºå—ï¼‰
   */
  async incrementalSync(poolAddress: string): Promise<void> {
    try {
      console.log(`ğŸš€ Starting incremental sync for pool ${poolAddress} on ${this.chain}`);
      
      const latestBlock = await this.getLatestBlockNumber();
      console.log(`ğŸ“Š Latest block number: ${latestBlock}`);
      
      // è·å–Swapäº‹ä»¶çš„åŒæ­¥è¿›åº¦
      const swapProgress = await this.getSyncProgress(poolAddress, 'swap');
      let startBlock: bigint;
      
      if (swapProgress) {
        startBlock = swapProgress.lastBlockNumber + 1n;
        console.log(`ğŸ“ˆ Found existing sync progress - resuming from block ${startBlock}`);
      } else {
        startBlock = await this.getContractCreationBlock(poolAddress);
        console.log(`ğŸ†• No existing sync progress - starting from contract creation block ${startBlock}`);
      }
      
      if (startBlock <= latestBlock) {
        const blocksToSync = latestBlock - startBlock + 1n;
        console.log(`ğŸ”„ Syncing ${blocksToSync} blocks (${startBlock} to ${latestBlock}) for pool ${poolAddress}`);
        
        await this.syncEventsBatch(poolAddress, startBlock, latestBlock);
        
        console.log(`âœ… Incremental sync completed for pool ${poolAddress}`);
      } else {
        console.log(`â„¹ï¸  Pool ${poolAddress} is already up to date (start: ${startBlock}, latest: ${latestBlock})`);
      }
    } catch (error) {
      console.error(`âŒ Failed to perform incremental sync for pool ${poolAddress}:`, error);
      throw error;
    }
  }
}

export { TRADER_JOE_EVENTS };
